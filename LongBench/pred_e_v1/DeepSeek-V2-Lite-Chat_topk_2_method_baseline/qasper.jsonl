{"pred": " FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney.", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": " The UPA model uses the most recent text as the latent context for prediction.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": " The article does not provide specific information on other evaluation metrics looked at.", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": " The baselines were the models that use plain stacked LSTMs.", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": " jiant is compatible with models in any programming language.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": " The article states that \"every question in the test set is answered by at least two additional experts.\" This suggests that the experts are used to provide additional answers to the questions, but it does not explicitly state that they are comparable to real-world users. Therefore, the answer to the question is \"unanswerable\".", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": " No, the method does not help in sentiment classification task improvement.", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": " The datasets used in evaluation are English reviews and restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian).", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": " The improvements in small-scale unbalanced datasets when sentence representation is enhanced with topic information are 7.36% on accuracy and 9.69% on F1 score.", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": " They use transcribed text from the audio.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": " The article does not specify the clustering algorithms used.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": " BERT (Bidirectional Encoder Representations from Transformers) was used.", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": " The pivot-based baselines mentioned in the article are traditional transfer learning, pivot-based method, and multilingual NMT (MNMT).", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": " The datasets used were Friends and EmotionPush.", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": " Several evaluation protocols for each part of the database.", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": " The Gaussian-masked directional multi-head attention works by adjusting the weight between characters and their adjacent characters to a larger value which stands for the effect of adjacent characters. It ensures that the Gaussian weight only relies on the distance between characters.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": " Unanswerable", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": " In cases where attention is distributed over multiple source words where their relevance is not entirely obvious, such as in the words \"would\" and \"like\" as shown in Figure FIGREF1.", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": " They use a Recurrent Neural Network (RNN) for end-to-end speech recognition.", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": " The baseline mentioned in the article is the Support Vector Machine (SVM) with features like gazetteer list and Hidden Markov Model (HMM) with n-gram technique.", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": " The paper is published in 2020.", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": " Around 500 different workers were involved in the annotation of the evaluation study of table-to-text models.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": " The models used in the experiment are a linear SVM trained on word unigrams, a bidirectional Long Short-Term-Memory (BiLSTM) model, and a Convolutional Neural Network (CNN) model based on the architecture of BIBREF15.", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": " They explore BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF, CNN, and Stanford CRF models.", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": " Unanswerable.", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": " BERTbase model", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": " five keyphrase extraction models: TopicRank, WINGNUS, KP-miner, unsupervised graph-based ranking approach, and the last two among the top performing systems in the SemEval-2010 keyphrase extraction task.", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": " unanswerable", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": " MIMIC-III database containing electronic health records of patients admitted to an ICU at Beth Israel Deaconess Medical Center between 2001 and 2012.", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": " unanswerable", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": " The attention model captures other information rather than only the translational equivalent in the case of verbs.", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": " The baselines include bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN with GloVe, and the proposed model.", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": " They look at 19 different algorithms to recommend tags for annotating e-books.", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": " Transformer base architecture with 3 encoder layers, 3 decoder layers, and 0.3 dropout.", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": " They used two standard datasets, the Penn Treebank (PTB) and WikiText2 (WT-2).", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": " unanswerable", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": " The prior knowledge distillation techniques are ineffective in producing student models with vocabularies different from the original teacher models because they require the student and teacher models to share the same vocabulary and output space, which profoundly limits their potential to further reduce model sizes.", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": " The baseline method used is the word2vec algorithm.", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": " The ancient Chinese dataset comes from ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": " unanswerable", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": " Based on the paper, the more predictive set of features to detect fake news are words embeddings, style, and morality features.", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": " The datasets used for evaluation are XNLI dataset for classification task and Universal Dependencies v2.4 for parsing task.", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": " unanswerable", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": " unanswerable", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": " The collection of COVID-19 literature is comprised of over 45,000 scholarly articles, including over 33,000 with full text.", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": " The proposed model is compared to baseline models that have never been applied to the medical term abbreviation disambiguation task.", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": " unanswerable", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": " Macaw has a modular design, allowing for the configuration of different user interfaces or addition of new modules such as retrieval modules.", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": " Unanswerable.", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": " unanswerable", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": " The experiments were conducted on the SQuAD dataset.", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": " They train their models on the relation classification dataset of the SemEval 2010 task 8.", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": " The corpora they trained ELMo on consisted of the English Wikipedia dump from February 2017 for English, and a concatenation of the Russian Wikipedia dump from December 2018 and the full Russian National Corpus for Russian. The English Wikipedia corpus was two times larger than the Russian corpus.", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": " unanswerable", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": " The method improvements of F1 for paraphrase identification are that using the proposed DSC loss (dice loss) in replacement of the standard cross-entropy loss leads to significant performance boost.", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": " They maximize Fisher Information Ratio criteria by substituting Eq. (EQFORM0) into INLINEFORM3.", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": " The encoder has one LSTM layer.", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": " The dataset contains human-generated questions.", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": " The article does not mention any other baselines tested to compare with the neural baseline. Therefore, the answer is \"unanswerable\".", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": " The new corpus consists of 53 documents.", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": " Food.com", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": " They perform intrinsic evaluations consisting of word similarity and word analogy tasks, as well as downstream tasks.", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": " unanswerable", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": " The average length of the essays is roughly from 150 to 250 tokens.", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": " unanswerable", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": " Unanswerable", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": " The Random Kitchen Sink (RKS) approach is a method for mapping data vectors to a space where linear separation is possible, used for natural language processing tasks.", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": " They compare to a variant where they share token embeddings between the encoder and decoder.", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": " The results on both datasets showed that making use of artificial data provided improvements for all data generation methods, with the pattern-based method consistently outperforming the system by Felice2014a and the combination of the pattern-based method with the machine translation approach giving further substantial improvements and the best performance on all datasets.", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": " unanswerable", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": " Seven experts with legal training were used for annotation.", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": " Conditional Random Fields, Support Vector Machine, Hidden Markov Model, Maximum Entropy, Maximum Matching, and Conditional Random Fields.", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": " Stanford NER, spaCy 2.0, and a recurrent model similar to BIBREF13, BIBREF14 using bidirectional LSTM cells for character-based feature extraction and CRF.", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": " WordNet and Freebase.", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": " The article does not specify a baseline model.", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": " They addressed personal attack and racism.", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": " No", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": " an annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": " The Nguni languages are similar to each other.", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": " The sentiment analysis dataset used is the IMDb dataset of movie reviews.", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": " The classifier used in the study achieved a high accuracy and F1-score of 89.6% and 89.2%, respectively, indicating robust performance in the absence of model and parameter bias.", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": " AEM outperforms K-means, LEM, and DPEMM.", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": " PolyResponse engine is used in 8 languages for restaurant search and booking system: English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade).", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": " The sources of the datasets are Deutsche Welle's news website (http://www.dw.com/).", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": " The article does not provide information on whether the lexicon is the same for all languages. Therefore, the answer is \"unanswerable\".", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": " InferSent, Universal Sentence Encoder, and SentEval.", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": " SentEval transfer tasks.", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": " unanswerable", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": " The use of context tweets is proposed as an additional feature in understanding the abusive language.", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": " Yes", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": " Yes, they build a model to automatically detect demographic, linguistic or psychological dimensions of people.", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": " The best performing model among the author's submissions is the multi-granularity loss configuration, which achieved an F1 score of 0.673 on the development set.", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": " The two corpora used in the shared task correspond to the diachronic corpus pair from BIBREF0: DTA18 and DTA19. They consist of subparts of DTA corpus BIBREF11 which is a freely available lemmatized, POS-tagged and spelling-normalized diachronic corpus of German containing texts from the 16th to the 20th century. DTA18 contains 26 million sentences published between 1750-1799 and DTA19 40 million between 1850-1899", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": " The dataset includes 10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs.", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), and Multi-layer Perceptron (MLP) classifiers have been trained.", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": " They propose extended middle context, a new context representation for CNNs for relation classification.", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": " The specific feature of the multi-granularity and multi-tasking neural architecture design is the joint detection of propagandistic fragments and its type, as well as the performance of fragment detection and 19-way classification.", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": " The CORD-19 dataset is a collection of over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses. These articles are contributed by hospitals and medical institutes all over the world.", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": " The size of the real-life dataset used in this paper is 4528 employees with 26972 sentences in the supervisor assessment corpus.", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": " The state of the art methods in grammar induction involve neural network-based approaches and probabilistic context-free grammars with continuous latent vectors.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": " The backoff strategies work by passing UNK-predicted words through unchanged, backing off to a neutral word, or falling back to a more generic word recognition model trained on a larger corpus.", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": " The DSTC2 dataset is used to learn behavior.", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": " BLEU-4, NIST-4, and ROUGE-4.", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": " The state-of-the-art models for comparison in the experiments are RC models (r-net and AoA), CNN and GRU text classifiers, and RC models (r-net and AoA) taking fact description as passage and plea as query.", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": " POS tagging information, morphological patterns, affixes, and stem templates are used as linguistics features.", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": " The semantically related words take larger values along the dimensions that correspond to the concept word-groups extracted from Roget's Thesaurus.", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": " The data used in the article is in English and German.", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": " No", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": " The two news domains that are country-independent are mainstream and disinformation news.", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": " Experiments are performed on CoinCollector and CookingWorld text-based games.", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": " The article does not mention any specific metrics being proposed. Therefore, the answer is \"unanswerable\".", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": " The article does not explicitly mention the biases that the model captures. Therefore, the answer is \"unanswerable\".", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": " The article does not list specific future improvements. However, it mentions that \"an interesting perspective might be to further constrain the model on the data structure in order to prevent inaccurate or even contradictory descriptions.\" This suggests that future improvements could involve refining the model to avoid generating incorrect or inconsistent descriptions.", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": " The additive modification to the objective function is to introduce an additional cost term that favors an increase in the value of the embedding vector dimension corresponding to the concept word-group.", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": " No, they do not report results only on English data.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": " The novel aspect of their document-level encoder is that it is based on Bert and can encode a document and obtain representations for its sentences.", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": " The adaptive $\\alpha$ values in the proposed model allow for the learning of different sparsity patterns for each attention head, which leads to more variance in individual head behavior and clearer distinctions between dense and sparse heads. This increased diversity in head behavior and the ability to learn different sparsity patterns in the same span of context tokens contribute to better interpretability compared to the fixed case of $\\alpha =1.5$ in softmax Transformers.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": " unanswerable", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": " They look at 22,880 users.", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": " unanswerable", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": " The datasets contain two types of labels for antisocial events: \"Conversations Gone Awry\" dataset contains labels based on whether a personal attack occurs within the conversation or remains civil, and the \"ChangeMyView\" dataset uses labels to indicate whether a comment is removed by a moderator due to \"rude or hostile\" behavior.", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": " The experiment uses a dataset consisting of randomly collected INLINEFORM0 cases from China Judgments Online, with INLINEFORM1 cases for training, INLINEFORM2 for validation, and INLINEFORM3 cases for testing. INLINEFORM4 cases are granted divorce, while INLINEFORM5 cases are not. INLINEFORM6 cases contain valid pleas with INLINEFORM7 supported and INLINEFORM8 rejected. INLINEFORM9 relevant law articles are present, with INLINEFORM10 tokens on average.", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": " They measure style transfer success by calculating the root mean square error between the scores given by three evaluators for each pair of sentences, where a score of +1 indicates more formal, +1 indicates more informal, and 0 indicates neither.", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": " This method improves over the best performing state-of-the-art by generating more sensational headlines without using human-annotated data, and by effectively leveraging noisy sensationalism rewards through a novel loss function, Auto-tuned Reinforcement Learning (ARL).", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": " The human evaluations were based on the adequacy, fluency, and relative ranking values of the translation outputs. A group of 50 native speakers proficient in both English and Tamil languages served as annotators for the evaluation, and a collection of around 100 sentences from the test set results was used to ensure objectivity of the evaluation. The intra-annotator values for adequacy, fluency, and ranking were computed, and the scores are shown in Table TABREF32.", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": " They use a joint model that integrates visual features learned through Inception V3 with textual features learned through a biLSTM.", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": " The baseline was a weak model without using any monolingual data.", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": " The global network features that quantify different aspects of the sharing process include:\n\n1. Number of Strongly Connected Components (SCC)\n2. Size of the Largest Strongly Connected Component (LSCC)\n3. Number of Weakly Connected Components (WCC)\n4. Size of the Largest Weakly Connected Component (LWCC)\n5. Diameter of the Largest Weakly Connected Component (DWCC)\n6. Average Clustering Coefficient (CC)\n7. Main K-core Number (KC)\n8. Density (d)\n9. Structural virality of the largest", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": " The baseline is the performance of the models without pretraining, using simple lookup table embeddings learned from scratch.", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": " The core component for KBQA is the relation detection model, which is improved by the hierarchical matching approach using residual learning.", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": " The off-the-shelf reward learning algorithm from RL for joint data manipulation learning and model training adapted is the one inspired by BIBREF7.", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": " The article does not specify the exact dataset used, so the answer is \"unanswerable\".", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": " unanswerable", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": " The models decide the importance of output words by estimating the word importance using a gradient-based method that exploits the gradients in NMT generation. Specifically, they employ the integrated gradients method (IG) to attribute the output to the input words with the integration of first-order derivatives.", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": " unanswerable", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": " The augmentation method consistently outperforms the weighting method in the low-data setting, and our data weighting approach greatly improves classification performance in class-imbalance problems.", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": " The article does not explicitly mention Reading Comprehension or multiple choice question answering as the focus of the study. Therefore, the answer is unanswerable.", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": " The article mentions two datasets used: Waseem and Hovey BIBREF5 and Davidson et al. BIBREF9 datasets.", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": " They test their word importance approach on Transformer and RNN-Search model architectures.", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": " The article does not provide specific information on how keyphrase diversity is measured. Therefore, the answer is \"unanswerable\".", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": " The proposed evaluation for this task is based on the correlation of the collected importance estimates for propositions with the manual responsiveness scores assigned during TAC in comparison to ROUGE-2 and Pyramid scores.", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": " They compared LSTM models with 6-layers, 7-layers, 8-layers, 9-layers, and 2-layers models.", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": " The machine translation introduces the artifacts.", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": " KAR is an end-to-end MRC model.", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": " Future work plans include improving the sensationalism scorer and investigating the applications of dynamic balancing methods between RL and MLE in textGAN.", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": " The dataset models characters' profiles by collecting HLAs (Human Level Attributes) from TV Tropes, a knowledge-based website dedicated to pop culture, containing information on a plethora of characters from a variety of sources. These attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics.", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": " The dataset used in this work is the Reuters-8 dataset without stop words from BIBREF27.", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": " The accuracy merits of the approach are demonstrated by the significant improvements in accuracy and area under the precision-recall curve (AUC) for both Logistic Regression (LR) and Multilayer Perceptron (MLP) models when compared to the baseline methods.", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": " The authors present evidence that the model can capture some biases in data annotation and collection by discussing the misclassifications of hate samples as offensive and the misclassifications of offensive samples as hate, which are largely due to the biases in the collected data. They also mention the manual inspection of samples and the recent studies that highlight the biases in data collection and annotation.", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": " The article does not provide specific benchmarks where the state of the art is achieved. Therefore, the answer is \"unanswerable\".", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": " The model is more reliable for correcting grammatical, spelling, and word order errors.", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": " The authors crawled over 2M tweets from twitter to build a dataset with 262,755 ironic and 112,330 non-ironic tweets.", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": " Global context refers to the broader context of the entire document, while local context refers to the specific context within each sentence or topic segment.", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": " KBQA stands for Knowledge Base Question Answering.", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": " They utilized LDA and Gibbs sampling to evaluate ISWC and WWW publications by applying the LDA algorithm and Gibbs sampling on the publications from 2013-2017.", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": " No", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": " Women represent 33.16% of the speakers, and 22.57% of the total speech time.", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": " The baseline model was a system based on extractive summarization.", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": " Unanswerable", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": " The evaluation criteria and metrics used to evaluate the generated text include BLEU, METEOR, ROUGE-L, CIDEr, and the E2E NLG Challenge test data metrics.", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": " They used a content-based classifier for their system.", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": " CyberAttack and PoliticianDeath datasets.", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": " The machine learning and deep learning methods used for RQE are Logistic Regression and Recurrent Neural Networks (RNNs).", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": " The strong baseline in this context refers to the Seq2Seq model with attention and conditional copy as the base model.", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": " The invertibility condition is that the neural projector must be invertible and volume-preserving.", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": " Logistic Regression (LR) and Multilayer Perceptron (MLP) are used as target models.", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": " The real-world civil case dataset consists of 62 relevant law articles, with each article containing an average of INLINEFORM9 tokens. The dataset also includes 400 cases for training, 400 cases for validation, and 400 cases for testing, with INLINEFORM0 cases granted divorce and INLINEFORM1 cases not granted divorce. The total valid pleas for judgment prediction in civil cases are INLINEFORM4, with INLINEFORM5 supported and INLINEFORM6 rejected.", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": " The data was collected based on script scenarios rather than specific texts, resulting in question-answer pairs involving commonsense knowledge.", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": " The methods used to reduce data sparsity effects are the use of back-translated texts and the mix-source approach.", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": " ALOHA combined with the HLAs and dialogue dataset outperforms the baselines significantly, as observed from Table TABREF44.", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": " The distinctive characteristics of how Arabic speakers use offensive language include the use of animal analogies, insults targeting mental abilities, indirect speech, wishing evil, name alteration, societal stratification, immoral behavior, and sexually related expressions.", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": " The authors show that their learned policy generalizes better than existing solutions to unseen games by using the 4,440 games of \"First TextWorld Problems\" and demonstrating the effectiveness of the proposed approach in terms of improved generalization and sample efficiency compared to existing methods.", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": " unanswerable", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": " They build a predictive model based on linguistic features to classify dogmatic posts from Reddit.", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": " Yes, they released their data set of academic papers.", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": " unanswerable", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": " They use the gradient-based method to estimate the word importance and identify input words that are under-translated by NMT models based on their smaller contribution to the translated sentence.", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": " The model is applied to two datasets: the `Conversations Gone Awry' dataset from BIBREF9 and the subreddit ChangeMyView (CMV) dataset.", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": " Yes, they collected their own data by obtaining Japanese-Vietnamese parallel data from TED talks extracted from WIT3's corpus.", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": " Europarl corpus.", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": " Yes", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": " A second order co-occurrence matrix is a method used to measure semantic relatedness and similarity between two concepts by incorporating contextual information using the term pair's definition and their pairwise semantic similarity scores derived from a taxonomy.", "answers": ["frequencies of the other words which occur with both of them (i.e., second order co–occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
{"pred": " The evaluation metrics reported are precision, recall, F1 and accuracy.", "answers": ["precision, recall, F1 and accuracy", "precision, recall, F1 , accuracy "], "all_classes": null, "length": 4101}
{"pred": " No", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 4770}
{"pred": " They match annotators to instances by routing difficult examples to experts and easier ones to crowd annotators.", "answers": ["Annotations from experts are used if they have already been collected."], "all_classes": null, "length": 4377}
{"pred": " The dataset comprises approximately 2,100 texts and a total of approximately 14,000 questions.", "answers": ["13,939"], "all_classes": null, "length": 4489}
{"pred": " Yes, the data is de-identified with digital zeros and [de-identified] tags.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4592}
{"pred": " Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4457}
{"pred": " The evaluation methods used are ROGUE-1 Recall, ROGUE-1 Precision, ROGUE-2, ROGUE-L, INLINEFORM0, INLINEFORM1, and human evaluation.", "answers": ["Quantitative evaluation methods using ROUGE, Recall, Precision and F1.", "standard ROGUE metric, Recall, Precision and INLINEFORM0 scores for ROGUE-1,  INLINEFORM2 scores for ROGUE-2 and ROGUE-L"], "all_classes": null, "length": 4395}
{"pred": " The baseline methods are:\n1. Naive: A non-domain-adaptive baseline with bag-of-words representations and SVM classifier trained on the source domain.\n2. mSDA BIBREF7: This is the state-of-the-art method based on discrete input features.\n3. NaiveNN: This is a non-domain-adaptive CNN trained on source domain, which is a variant of our model by setting INLINEFORM0, INLINEFORM1, and INLINEFORM2 to zeros.\n4. AuxNN BIBREF4: This is a neural model that exploits auxiliary", "answers": ["(1) Naive, (2) mSDA BIBREF7, (3) NaiveNN, (4) AuxNN BIBREF4, (5) ADAN BIBREF16, (6) MMD", "non-domain-adaptive baseline with bag-of-words representations and SVM classifier, mSDA, non-domain-adaptive CNN trained on source domain, neural model that exploits auxiliary tasks, adversarial training to reduce representation difference between domains, variants of deep CNNs are used for encoding images and the MMDs of multiple layers are jointly minimized"], "all_classes": null, "length": 5063}
{"pred": " The joint model achieves an accuracy of 59.4% on Wikipedia and is statistically significant (p<0.05) compared to using textual features alone (biLSTM) and visual features alone (Inception).", "answers": ["59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"], "all_classes": null, "length": 4203}
{"pred": " The paper mentions word embedding techniques such as word2vec, which have become very popular.", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null, "length": 4259}
{"pred": " The two large-scale datasets used are the US dataset and the Italian dataset.", "answers": ["US dataset, Italian dataset", "US dataset, Italian dataset"], "all_classes": null, "length": 4857}
{"pred": " Political handles engage in more profile change behavior than follower accounts. Certain profile attributes are changed more frequently among political accounts and follower accounts, with subtle differences in the behavior of political and follower accounts.", "answers": ["Influential leaders are more likely to change their profile attributes than their followers; the leaders do not change their usernames, while their followers change their usernames a lot; the leaders  tend to make new changes related to previous attribute values, while the followers make comparatively less related changes to previous attribute values."], "all_classes": null, "length": 5092}
{"pred": " They conducted a human study to evaluate the performance on CBT validation and test datasets.", "answers": [" by testing humans on a random subset of 50 named entity and 50 common noun validation questions that the psr ensemble could not answer correctly", "majority of questions that our system could not answer so far are in fact answerable"], "all_classes": null, "length": 4232}
{"pred": " The article does not specify which metrics are used in evaluation. Therefore, the answer is \"unanswerable\".", "answers": ["precision, recall , F1 score"], "all_classes": null, "length": 4515}
{"pred": " No, the article mentions the use of multiple datasets, including English and other languages.", "answers": ["Unanswerable", "Yes"], "all_classes": null, "length": 7251}
{"pred": " The Wikipedia dataset consists of articles from English Wikipedia, with a dataset of around 29,794 articles.", "answers": ["a sample of  29,794 wikipedia articles and 2,794 arXiv papers "], "all_classes": null, "length": 4187}
{"pred": " No, they do not recommend translating the premise and hypothesis together.", "answers": ["No", "No"], "all_classes": null, "length": 4071}
{"pred": " The effectiveness of LiLi in terms of both predictive quality and strategy formulation ability.", "answers": ["Coverage, Avg. MCC and avg. +ve F1 score", "strategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score"], "all_classes": null, "length": 5869}
{"pred": " They use a combination of supervised learning, unsupervised learning, and topic modeling approaches towards text analysis.", "answers": ["Domain experts and fellow researchers can provide feedback on questions and help with dynamically revising them., connect to multiple disciplines, dual use", "Modeling considerations:  the variables (both predictors and outcomes)  are rarely simply binary or categorical;  using a particular classification scheme means deciding which variations are visible,; Supervised and unsupervised learning are the most common approaches to learning from data;  the unit of text that we are labeling (or annotating, or coding), either automatic or manual, can sometimes be different than one's final unit of analysis."], "all_classes": null, "length": 8530}
{"pred": " unanswerable", "answers": ["Unanswerable"], "all_classes": null, "length": 8508}
{"pred": " The Energy sector achieved the best performance.", "answers": ["Energy with accuracy of 0.538", "Energy"], "all_classes": null, "length": 10349}
{"pred": " The article does not provide specific background information about the authors or researchers involved in the study. Therefore, the answer is unanswerable.", "answers": ["Unanswerable"], "all_classes": null, "length": 8506}
{"pred": " SVMhmm implementation of Structural Support Vector Machines for sequence labeling was used in experiments.", "answers": ["Structural Support Vector Machine", "SVMhmm "], "all_classes": null, "length": 14468}
{"pred": " Yes, they model semantics by using vector space models and word embeddings to represent the data and capture semantic relations between words.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12950}
{"pred": " The state of the art described in the paper is a hybrid conceptual architecture that supports decoupled interaction norms specification and a multi-party governance service that enforces exchange of compliant utterances. The authors are also exploring a micro-service implementation of SABIA to increase its scalability and performance, allowing thousands of members to join the system within thousands of conversations.", "answers": ["ELIZA,  PARRY, A.L.I.C.E., Cleverbot"], "all_classes": null, "length": 13395}
{"pred": " They use a dataset from the UN General Debate Corpus.", "answers": ["corpus of state speeches delivered during the annual UN General Debate", "corpus of state speeches delivered during the annual UN General Debate"], "all_classes": null, "length": 8647}
{"pred": " The text embedding methodologies used are Doc2Vec (Doc2Vec) and paragraph vectors (PV).", "answers": ["Document to Vector (Doc2Vec)", "Doc2Vec, PV-DBOW model"], "all_classes": null, "length": 8196}
{"pred": " The ML methods aim to identify argument components such as claims, premises, backing, rebuttal, refutation, and non-argumentative text.", "answers": ["claim, premise, backing, rebuttal, and refutation", "claim, premise, backing, rebuttal, refutation"], "all_classes": null, "length": 14472}
{"pred": " No, they also report results on non-English data, such as Greek texts.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 14465}
{"pred": " The datasets used are related to finance and include a set of 124 questions asked by users and a set of 37 classes of intents derived from these questions. The second set of datasets consists of 37 classes of intents, with a total of 415 samples, ranging from 3 to 37 samples per class.", "answers": ["Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.", "a self-collected financial intents dataset in Portuguese"], "all_classes": null, "length": 13401}
{"pred": " No, they do not analyze specific derogatory words.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12952}
{"pred": " A node in the network approach represents a state or entity in the network.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 8641}
{"pred": " The data in the new corpus is sourced from user-generated Web content, specifically from comments and forum posts related to various controversial topics in education.", "answers": ["user comments to newswire articles or to blog posts, forum posts, blog posts, newswire articles", "refer to each article, blog post, comment, or forum posts as a document"], "all_classes": null, "length": 14481}
{"pred": " They extract paragraphs containing any word from a predetermined list of LGTBQ terms (shown in Table TABREF19) from the New York Times data.", "answers": ["act paragraphs containing any word from a predetermined list of LGTBQ terms "], "all_classes": null, "length": 12970}
{"pred": " Yes, they discuss the importance of interdisciplinary insights in the article.", "answers": ["No", "No"], "all_classes": null, "length": 8509}
{"pred": " The issues that are not always at the forefront of discussions about computational text analysis methods include working with thick social and cultural concepts, operationalizations, and validation.", "answers": ["identifying the questions we wish to explore, Can text analysis provide a new perspective on a “big question” that has been attracting interest for years?, How can we explain what we observe?, hope to connect to multiple disciplines"], "all_classes": null, "length": 8555}
{"pred": " The evaluation metrics looked at were the time taken to answer an utterance and other resource consumption metrics (e.g., memory, CPU, network bandwidth). The framework was designed to validate CognIA's implementation, check if the bots are answering correctly given a pre-defined set of known dialogues, and perform a performance analysis of the platform.", "answers": ["precision, recall, F1 and accuracy", "Response time, resource consumption (memory, CPU, network bandwidth), precision, recall, F1, accuracy."], "all_classes": null, "length": 13391}
{"pred": " No", "answers": ["No", "Yes"], "all_classes": null, "length": 8643}
{"pred": " The task of annotating and analyzing argumentation in user-generated Web content faces challenges in different registers and domains, as the data exhibits varying levels of linguistic variability, lack of established theoretical counterparts, and domain-specific characteristics.", "answers": ["linguistic variability"], "all_classes": null, "length": 14469}
{"pred": " The datasets were annotated by human raters who scored each pair in the dataset with an integer score between 0 and 6, indicating the degree of semantic similarity between the two words in a given pair. Annotators were required to score the entire set of 1,888 pairs in the dataset, and the pairs were not to be shared between different annotators. Annotators were also kept anonymous and were not allowed to communicate with each other during the annotation process.", "answers": ["1. Each annotator must assign an integer score between 0 and 6 (inclusive) indicating how semantically similar the two words in a given pair are. A score of 6 indicates very high similarity (i.e., perfect synonymy), while zero indicates no similarity., 2. Each annotator must score the entire set of 1,888 pairs in the dataset.,  able to use external sources (e.g. dictionaries, thesauri, WordNet) if required, not able to communicate with each other during the annotation process"], "all_classes": null, "length": 14722}
{"pred": " The article states that \"there are aspects of online argumentation that lack their established theoretical counterparts, such as rhetorical questions, figurative language, narratives, and fallacies in general.\" It also mentions that \"the capabilities of the model to capture argumentation depend on the register and topic, the length of the document, and inherently on the literary devices and structures used for expressing argumentation as these properties influenced the agreement among annotators.\"\n\nBased on this information, the answer to the question is: This work accounts for the phenomena of rhetorical questions, figurative language, narratives, and fallacies in general in actual data.", "answers": ["Unanswerable"], "all_classes": null, "length": 14471}
{"pred": " The 12 languages covered are Chinese Mandarin, Russian, French, Spanish, English, Finnish, Polish, Swedish, Dutch, Portuguese, Arabic, and Farsi.", "answers": ["Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese", "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese"], "all_classes": null, "length": 14660}
